{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from IPython.display import SVG, HTML\n",
    "import copy as copy\n",
    "\n",
    "\n",
    "_model_params_doc = \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: array-like\n",
    "        The dependent variable, dim = n*1\n",
    "    x: array-like\n",
    "        The independnet variable, dim = n*p. By default, an intercept is included.\n",
    "    weight: array-like\n",
    "        Each observation in the input data set is weighted by the value of the WEIGHT variable. By default, weight is np.ones(n)\n",
    "    method: ['forward', 'backward', 'stepwise']\n",
    "        The default selection method is 'stepwise'\n",
    "    maxiter: int\n",
    "        maxiter = 25 (default)\n",
    "    mindiff: float\n",
    "        mindiff = 1e-8 (default)\n",
    "    \"\"\"\n",
    "_models_Result_docs = \"\"\"\n",
    "    params: array\n",
    "        Parameters' Estimates\n",
    "    AIC: float\n",
    "        Akaike information criterion.  `-2*(llf - p)` where `p` is the number\n",
    "        of regressors including the intercept.\n",
    "    BIC: float\n",
    "        Bayesian information criterion. `-2*llf + ln(nobs)*p` where `p` is the\n",
    "        number of regressors including the intercept.\n",
    "    SC: float\n",
    "        Schwarz criterion. `-LogL + p*(log(nobs))`\n",
    "    std_error: Array\n",
    "        The standard errors of the coefficients.(bse)\n",
    "    Chi_Square: float\n",
    "        Wald Chi-square : (logit_res.params[0]/logit_res.bse[0])**2\n",
    "    Chisqprob: float\n",
    "        P-value from Chi_square test statistic \n",
    "    llf: float\n",
    "        Value of the loglikelihood, as (LogL)\n",
    "    \"\"\"    \n",
    "# Newton-Raphson Iteration\n",
    " \n",
    "class ModelInfo(object):\n",
    "    \n",
    "    def __init__(self, data, role, **kwargs):\n",
    "        self.data = sm.add_constant(data)\n",
    "        self.role = role\n",
    "        self.maxiter = 25   # default maxiter\n",
    "        self.mindiff = 1e-8 # default mindiff\n",
    "        self.method  = 'None'\n",
    "        self.slentry = 0.05  # default\n",
    "        self.slstay  = 0.05  # default\n",
    "        self.cont    = True  # default self.cont = True, include intercept in model        \n",
    "        if 'slentry' in kwargs.keys():\n",
    "            self.slentry = float(kwargs['slentry'])\n",
    "        if 'slstay' in kwargs.keys():\n",
    "            self.slstay = float(kwargs['slstay'])\n",
    "        if 'method' in kwargs.keys():\n",
    "            self.method = kwargs['method']\n",
    "        if 'maxiter' in kwargs.keys():\n",
    "            self.maxiter = kwargs['maxiter']\n",
    "        if 'mindiff' in kwargs.keys():\n",
    "            self.mindiff = kwargs['mindiff'] \n",
    "    def xcol(self):\n",
    "        #print(self.role)\n",
    "        #print(self.data.columns)\n",
    "        xcols = ['const']+[self.data.columns[i+1] for i, col in enumerate(self.role) if col == 1]\n",
    "        return xcols\n",
    "    def ycol(self):\n",
    "        ycols = [self.data.columns[i+1] for i, col in enumerate(self.role) if col == 2]\n",
    "        return ycols\n",
    "    def weight(self):\n",
    "        _weight_ = [self.data.columns[i+1] for i, col in enumerate(self.role) if col == 3]\n",
    "        return _weight_\n",
    "    def handledata(self, name):\n",
    "        data = []\n",
    "        for col in name:\n",
    "            data.append(self.data[col])\n",
    "        return np.array(data)\n",
    "    def xdata(self):\n",
    "        data = self.handledata(self.xcol())\n",
    "        return data\n",
    "    def ydata(self):\n",
    "        data = self.handledata(self.ycol())\n",
    "        return data\n",
    "    def _weight(self):\n",
    "        if 3 in self.role:\n",
    "            data = self.data[self.weight()]\n",
    "        else :\n",
    "            data = np.ones(self.data.shape[0])\n",
    "        return data\n",
    "\n",
    "class LRStats(object):\n",
    "    def __init__(self, step, n, p, res):\n",
    "        self.aic  = res.aic\n",
    "        self.bic  = res.bic\n",
    "        self.logl = -2*res.llf\n",
    "        self.sc   = 2*(-res.llf + p*(np.log(n)))\n",
    "        self.params = res.params\n",
    "        self.wald_chi = (res.params/res.bse)**2 \n",
    "        self.std_error = res.bse\n",
    "        self.pchi2 = 2*stats.norm.cdf(-np.abs((res.params/res.bse)))\n",
    "    def resprint(self):\n",
    "        print(\"                          Model Fit Statistics \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"AIC                   %s           BIC           %s    \" % (self.aic, self.bic))\n",
    "        print(\"-2Logl                %s           SC            %s    \" % (self.logl, self.sc))\n",
    "        print(\"==============================================================================\")\n",
    "\n",
    "        \n",
    "        \n",
    "class checkio(object):\n",
    "    def __init__(self,xwait,score,pvalue):\n",
    "        self.xwait = xwait\n",
    "        self.score = score\n",
    "        self.pvalue= pvalue\n",
    "    def enter(self):\n",
    "        print(\"              Analysis of Variables Eligible for Entry  \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"\\t%5s\\t \\t%5s\\t \\t%5s\\t\" % (\"variable\", \"Wald Chi-square\", \"Pr>ChiSq\"))\n",
    "        for i,v in enumerate(self.xwait):\n",
    "            print(\"    \\t%5s\\t             \\t%10s\\t     \\t%10s\\t\" % (v, self.score[i], self.pvalue[i]))\n",
    "        print(\" \") \n",
    "    def remove(self):\n",
    "        print(\"              Analysis of Variables Eligible for Remove  \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"\\t%5s\\t \\t%5s\\t \\t%5s\\t\" % (\"variable\", \"Wald Chi-square\", \"Pr>ChiSq\"))\n",
    "        for i,v in enumerate(self.xwait):\n",
    "            print(\"    \\t%5s\\t             \\t%10s\\t     \\t%10s\\t\" % (v, self.score[i], self.pvalue[i]))\n",
    "        print(\" \")\n",
    "        \n",
    "class GlobalNullTest(object):\n",
    "    def __init__(self,x,y,beta):\n",
    "        self.x  = x\n",
    "        self.p  = (x.shape[1] - 1)\n",
    "        self.y  = y\n",
    "        self.betai = pd.DataFrame(beta+[0.])\n",
    "    def score(self):\n",
    "        pi_value = 1/(1+np.exp(-1*np.dot(self.x, self.betai)))\n",
    "        u = np.dot( self.x.T, self.y-pi_value)\n",
    "        h = np.dot(np.dot(self.x.T, np.eye(len(self.y))*pi_value*(1-pi_value)), self.x)\n",
    "        score = np.dot(np.dot(u.T,np.linalg.inv(h)), u)\n",
    "        return list(score[0])\n",
    "    def pvalue(self):\n",
    "        pvalue = stats.chisqprob(self.score(), 1)\n",
    "        return list(pvalue)\n",
    "\n",
    "class StepwiseModel(ModelInfo):\n",
    "    def __init__(self, data, role, **kwargs):\n",
    "        super(StepwiseModel, self).__init__(data, role, **kwargs)\n",
    "        super(StepwiseModel, self).xcol()\n",
    "        super(StepwiseModel, self).ydata()\n",
    "    def logitreg(self):\n",
    "        n    = self.data.shape[0]\n",
    "        p    = self.data.shape[1]\n",
    "        y    = pd.DataFrame(self.ydata()[0], columns = ['y'])\n",
    "        xcol = self.xcol()\n",
    "        #xin  = np.ones(p)\n",
    "        #xout = np.zeros(p)\n",
    "        xenter= ['const']\n",
    "        xwait = copy.copy(xcol)\n",
    "        xwait.remove('const')\n",
    "        #xout   = [] \n",
    "        step   = 0\n",
    "        history = {}\n",
    "        print(\"**** The LogitReg Process ****\\n\")\n",
    "        print(\"** Step 0. Intercept entered:\\n\")\n",
    "        logit_mod = sm.Logit(self.ydata()[0],self.xdata()[0])\n",
    "        logit_res = logit_mod.fit(disp=0)\n",
    "        Beta0     = list(logit_res.params)\n",
    "        print(logit_res.summary())\n",
    "        history = LRStats(step,n,1,logit_res)\n",
    "        print(\" \")\n",
    "        history.resprint()\n",
    "        newx   = self.data['const']\n",
    "        for i in np.arange(p):\n",
    "            print(\"   \")\n",
    "            score  = []\n",
    "            pvalue = []\n",
    "            logit_res = {}\n",
    "            history   = {}\n",
    "            for xname in xwait:\n",
    "                _tmpx = np.vstack((newx, self.data[xname]))\n",
    "                _tmpxenter = xenter+[xname]\n",
    "                _tmpx = pd.DataFrame(_tmpx.T, columns = _tmpxenter)\n",
    "                logit_mod = sm.Logit(y,_tmpx)\n",
    "                _logit_res = logit_mod.fit(disp=0)\n",
    "                logit_res[xname] = _logit_res\n",
    "                _history = LRStats(step,n,1,_logit_res)\n",
    "                history[xname]   = _history\n",
    "                nulltest = GlobalNullTest(_tmpx, y, Beta0)\n",
    "                score  = score + list(nulltest.score())\n",
    "                pvalue = pvalue + list(nulltest.pvalue())\n",
    "                #xin += 1\n",
    "            checkenter = checkio(xwait, score, pvalue)\n",
    "            checkenter.enter()\n",
    "            if (min(pvalue) <= self.slentry):\n",
    "                # Update newx and xenter\n",
    "                xin = [xwait[ii] for ii,pv in enumerate(pvalue) if pv == min(pvalue)][0]\n",
    "                xenter = xenter+[xin]\n",
    "                newx = np.vstack((newx, self.data[xin]))\n",
    "                newx = pd.DataFrame(newx.T, columns = xenter)                \n",
    "                xwait.remove(xin)\n",
    "                step += 1\n",
    "                print(\"** step %s: %s entered:\\n\"%(step,xin))\n",
    "                print(logit_res[xin].summary())\n",
    "                Beta0     = list(logit_res[xin].params)\n",
    "                history[xin].resprint()\n",
    "                pouttest    = history[xin].pchi2[1:]\n",
    "                waldouttest = history[xin].wald_chi[1:]\n",
    "                xouttest    = xenter[1:]\n",
    "                checkout    = checkio(xouttest, waldouttest, pouttest)\n",
    "                checkout.remove()\n",
    "                while 1:\n",
    "                    if (max(pouttest) <= self.slstay):\n",
    "                        print(\"         No (additional) Variables met the %s significance level for remove into the model\"%(self.slstay))\n",
    "                        break\n",
    "                    else :\n",
    "                        _slrindex = pouttest.index(max(pouttest))\n",
    "                        xout = xouttest[_slrindex]\n",
    "                        step += 1\n",
    "                        print(\"step %s: %s removed:\\n\"%(step, xout))\n",
    "                        # Update newx and xenter\n",
    "                        del newx[xout]\n",
    "                        xenter.remove(xout)\n",
    "                        xwait.remove(xout)\n",
    "                        logit_mod = sm.Logit(y,newx)\n",
    "                        _logit_res= logit_mod.fit(disp=0)\n",
    "                        Beta0     = list(_logit_res.params)\n",
    "                        _logit_res.summary()\n",
    "                        _history  = LRStats(step,n,1,_logit_res)\n",
    "                        _history.resprint()\n",
    "                        pouttest  = history[xin].pchi2[1:]\n",
    "                        waldouttest= history[xin].wald_chi[1:]\n",
    "                        xouttest   = xenter[1:]\n",
    "                        checkout   = checkio(xouttest, waldouttest, pouttest)\n",
    "                        checkout.remove()                \n",
    "            else :\n",
    "                print(\"    No (additional) Variables met the %s significance level for entry into the model\"%(self.slentry))\n",
    "                break\n",
    "            newx = newx.T\n",
    "            i += 1\n",
    "        result = {}\n",
    "        for iii, b in enumerate(Beta0):\n",
    "            result[xenter[iii]] = b\n",
    "        return result\n",
    "    def beta(self):\n",
    "        _beta = self.logitreg()\n",
    "        return _beta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('/home/dzn/Project/d05_scorecard/d01_LogisticRegression/data/x.csv', sep = ',')\n",
    "role  = [1,1,1,1,1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
