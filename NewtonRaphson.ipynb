{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG, HTML\n",
    "import copy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('/home/dzn/Project/d05_scorecard/d01_LogisticRegression/data/x.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>smear</th>\n",
       "      <th>infil</th>\n",
       "      <th>li</th>\n",
       "      <th>blast</th>\n",
       "      <th>temp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cell  smear  infil   li  blast   temp  y\n",
       "0   0.8   0.83   0.66  1.9   1.10  0.996  1\n",
       "1   0.9   0.36   0.32  1.4   0.74  0.992  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datanames = data.columns\n",
    "role      = [1,1,1,1,1,1,2]\n",
    "[n,p] = data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelInfo(object):\n",
    "    def __init__(self, data, role, **kwargs):\n",
    "        self.data = sm.add_constant(data)\n",
    "        self.role = role\n",
    "        self.maxiter = 25   # default maxiter\n",
    "        self.mindiff = 1e-8 # default mindiff\n",
    "        self.method  = 'None'\n",
    "        self.slentry = 0.05  # default\n",
    "        self.slstay  = 0.05  # default\n",
    "        self.cont    = True  # default self.cont = True, include intercept in model        \n",
    "        if 'slentry' in kwargs.keys():\n",
    "            self.slentry = float(kwargs['slentry'])\n",
    "        if 'slstay' in kwargs.keys():\n",
    "            self.slstay = float(kwargs['slstay'])\n",
    "        if 'method' in kwargs.keys():\n",
    "            self.method = kwargs['method']\n",
    "        if 'maxiter' in kwargs.keys():\n",
    "            self.maxiter = kwargs['maxiter']\n",
    "        if 'mindiff' in kwargs.keys():\n",
    "            self.mindiff = kwargs['mindiff'] \n",
    "    def xcol(self):\n",
    "        #print(self.role)\n",
    "        #print(self.data.columns)\n",
    "        xcols = ['const']+[self.data.columns[i+1] for i, col in enumerate(self.role) if col == 1]\n",
    "        return xcols\n",
    "    def ycol(self):\n",
    "        ycols = [self.data.columns[i+1] for i, col in enumerate(self.role) if col == 2]\n",
    "        return ycols\n",
    "    def weight(self):\n",
    "        _weight_ = [self.data.columns[i+1] for i, col in enumerate(self.role) if col == 3]\n",
    "        return _weight_\n",
    "    def handledata(self, name):\n",
    "        data = []\n",
    "        for col in name:\n",
    "            data.append(self.data[col])\n",
    "        return np.array(data)\n",
    "    def xdata(self):\n",
    "        data = self.handledata(self.xcol())\n",
    "        return data\n",
    "    def ydata(self):\n",
    "        data = self.handledata(self.ycol())\n",
    "        return data\n",
    "    def _weight(self):\n",
    "        if 3 in self.role:\n",
    "            data = self.data[self.weight()]\n",
    "        else :\n",
    "            data = np.ones(self.data.shape[0])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LRStats(object):\n",
    "    def __init__(self, step, n, p, res):\n",
    "        self.aic  = res.aic\n",
    "        self.bic  = res.bic\n",
    "        self.logl = -2*res.llf\n",
    "        self.sc   = 2*(-res.llf + p*(np.log(n)))\n",
    "        self.params = res.params\n",
    "        self.wald_chi = (res.params/res.bse)**2 \n",
    "        self.std_error = res.bse\n",
    "        self.pchi2 = 2*stats.norm.cdf(-np.abs((res.params/res.bse)))\n",
    "    def resprint(self):\n",
    "        print(\"                          Model Fit Statistics \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"AIC                   %s           BIC           %s    \" % (self.aic, self.bic))\n",
    "        print(\"-2Logl                %s           SC            %s    \" % (self.logl, self.sc))\n",
    "        print(\"==============================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class checkio(object):\n",
    "    def __init__(self,xwait,score,pvalue):\n",
    "        self.xwait = xwait\n",
    "        self.score = score\n",
    "        self.pvalue= pvalue\n",
    "    def enter(self):\n",
    "        print(\"              Analysis of Variables Eligible for Entry  \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"\\t%5s\\t \\t%5s\\t \\t%5s\\t\" % (\"variable\", \"Wald Chi-square\", \"Pr>ChiSq\"))\n",
    "        for i,v in enumerate(self.xwait):\n",
    "            print(\"    \\t%5s\\t             \\t%10s\\t     \\t%10s\\t\" % (v, self.score[i], self.pvalue[i]))\n",
    "        print(\" \") \n",
    "    def remove(self):\n",
    "        print(\"              Analysis of Variables Eligible for Remove  \")\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"\\t%5s\\t \\t%5s\\t \\t%5s\\t\" % (\"variable\", \"Wald Chi-square\", \"Pr>ChiSq\"))\n",
    "        for i,v in enumerate(self.xwait):\n",
    "            print(\"    \\t%5s\\t             \\t%10s\\t     \\t%10s\\t\" % (v, self.score[i], self.pvalue[i]))\n",
    "        print(\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GlobalNullTest(object):\n",
    "    def __init__(self,x,y,beta):\n",
    "        self.x  = x\n",
    "        self.p  = (x.shape[1] - 1)\n",
    "        self.y  = y\n",
    "        self.betai = pd.DataFrame(beta+[0.])\n",
    "    def score(self):\n",
    "        pi_value = 1/(1+np.exp(-1*np.dot(self.x, self.betai)))\n",
    "        u = np.dot( self.x.T, self.y-pi_value)\n",
    "        h = np.dot(np.dot(self.x.T, np.eye(len(self.y))*pi_value*(1-pi_value)), self.x)\n",
    "        score = np.dot(np.dot(u.T,np.linalg.inv(h)), u)\n",
    "        return list(score[0])\n",
    "    def pvalue(self):\n",
    "        pvalue = stats.chisqprob(self.score(), 1)\n",
    "        return list(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StepwiseModel(ModelInfo):\n",
    "    def __init__(self, data, role, **kwargs):\n",
    "        super(StepwiseModel, self).__init__(data, role, **kwargs)\n",
    "        super(StepwiseModel, self).xcol()\n",
    "        super(StepwiseModel, self).ydata()\n",
    "    def logitreg(self):\n",
    "        n    = self.data.shape[0]\n",
    "        p    = self.data.shape[1]\n",
    "        y    = pd.DataFrame(self.ydata()[0], columns = ['y'])\n",
    "        xcol = self.xcol()\n",
    "        #xin  = np.ones(p)\n",
    "        #xout = np.zeros(p)\n",
    "        xenter= ['const']\n",
    "        xwait = copy.copy(xcol)\n",
    "        xwait.remove('const')\n",
    "        #xout   = [] \n",
    "        step   = 0\n",
    "        history = {}\n",
    "        print(\"**** The LogitReg Process ****\\n\")\n",
    "        print(\"** Step 0. Intercept entered:\\n\")\n",
    "        logit_mod = sm.Logit(self.ydata()[0],self.xdata()[0])\n",
    "        logit_res = logit_mod.fit(disp=0)\n",
    "        Beta0     = list(logit_res.params)\n",
    "        print(logit_res.summary())\n",
    "        history = LRStats(step,n,1,logit_res)\n",
    "        print(\" \")\n",
    "        history.resprint()\n",
    "        newx   = self.data['const']\n",
    "        for i in np.arange(p):\n",
    "            print(\"   \")\n",
    "            score  = []\n",
    "            pvalue = []\n",
    "            rb     = 0\n",
    "            logit_res = {}\n",
    "            history   = {}\n",
    "            for xname in xwait:\n",
    "                _tmpx = np.vstack((newx, self.data[xname]))\n",
    "                _tmpxenter = xenter+[xname]\n",
    "                _tmpx = pd.DataFrame(_tmpx.T, columns = _tmpxenter)\n",
    "                logit_mod = sm.Logit(y,_tmpx)\n",
    "                _logit_res = logit_mod.fit(disp=0)\n",
    "                logit_res[xname] = _logit_res\n",
    "                _history = LRStats(step,n,1,_logit_res)\n",
    "                history[xname]   = _history\n",
    "                nulltest = GlobalNullTest(_tmpx, y, Beta0)\n",
    "                score  = score + list(nulltest.score())\n",
    "                pvalue = pvalue + list(nulltest.pvalue())\n",
    "                #xin += 1\n",
    "            checkenter = checkio(xwait, score, pvalue)\n",
    "            checkenter.enter()\n",
    "            if (min(pvalue) <= self.slentry):\n",
    "                # Update newx and xenter\n",
    "                xin = [xwait[ii] for ii,pv in enumerate(pvalue) if pv == min(pvalue)][0]\n",
    "                xenter = xenter+[xin]\n",
    "                newx = np.vstack((newx, self.data[xin]))\n",
    "                newx = pd.DataFrame(newx.T, columns = xenter)                \n",
    "                xwait.remove(xin)\n",
    "                step += 1\n",
    "                print(\"** step %s: %s entered:\\n\"%(step,xin))\n",
    "                print(logit_res[xin].summary())\n",
    "                Beta0     = list(logit_res[xin].params)\n",
    "                history[xin].resprint()\n",
    "                pouttest    = history[xin].pchi2[1:]\n",
    "                waldouttest = history[xin].wald_chi[1:]\n",
    "                xouttest    = xenter[1:]\n",
    "                checkout    = checkio(xouttest, waldouttest, pouttest)\n",
    "                checkout.remove()\n",
    "                while 1:\n",
    "                    if (max(pouttest) <= self.slstay):\n",
    "                        print(\"         No (additional) Variables met the %s significance level for remove into the model\"%(self.slstay))\n",
    "                        break\n",
    "                    else :\n",
    "                        _slrindex = list(pouttest).index(max(pouttest))\n",
    "                        xout = xouttest[_slrindex]\n",
    "                        step += 1\n",
    "                        print(\"step %s: %s removed:\\n\"%(step, xout))\n",
    "                        # Update newx and xenter\n",
    "                        #print(xenter)\n",
    "                        #print(newx)\n",
    "                        del newx[xout]\n",
    "                        xenter.remove(xout)\n",
    "                        #xwait.remove(xout)\n",
    "                        logit_mod = sm.Logit(y,newx)\n",
    "                        _logit_res= logit_mod.fit(disp=0)\n",
    "                        Beta0     = list(_logit_res.params)\n",
    "                        _logit_res.summary()\n",
    "                        _history  = LRStats(step,n,1,_logit_res)\n",
    "                        _history.resprint()\n",
    "                        pouttest  = _history.pchi2[1:]\n",
    "                        waldouttest= _history.wald_chi[1:]\n",
    "                        xouttest   = xenter[1:]\n",
    "                        checkout   = checkio(xouttest, waldouttest, pouttest)\n",
    "                        checkout.remove()\n",
    "                        ij = 0\n",
    "                        if (xin == xout and ij == 0):\n",
    "                            print(\"Model building terminates because the last effect entered is removed by the Wald statistic criterion\")\n",
    "                            rb = 1\n",
    "                            break\n",
    "                        else :\n",
    "                            ij += 1\n",
    "                            rb = 2\n",
    "            else :\n",
    "                print(\"    No (additional) Variables met the %s significance level for entry into the model\"%(self.slentry))\n",
    "                break\n",
    "            if rb == 1:\n",
    "                break\n",
    "            newx = newx.T\n",
    "            i += 1\n",
    "        result = {}\n",
    "        for iii, b in enumerate(Beta0):\n",
    "            result[xenter[iii]] = b\n",
    "        return result\n",
    "    def beta(self):\n",
    "        _beta = self.logitreg()\n",
    "        return _beta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** The LogitReg Process ****\n",
      "\n",
      "** Step 0. Intercept entered:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   27\n",
      "Model:                          Logit   Df Residuals:                       26\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Wed, 20 Jan 2016   Pseudo R-squ.:                   0.000\n",
      "Time:                        15:06:12   Log-Likelihood:                -17.186\n",
      "converged:                       True   LL-Null:                       -17.186\n",
      "                                        LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6931      0.408     -1.698      0.090        -1.493     0.107\n",
      "==============================================================================\n",
      " \n",
      "                          Model Fit Statistics \n",
      "==============================================================================\n",
      "AIC                   36.3717650879           BIC           37.6676019539    \n",
      "-2Logl                34.3717650879           SC            40.9634388199    \n",
      "==============================================================================\n",
      "   \n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t cell\t             \t1.88933755878\t     \t0.169276657378\t\n",
      "    \tsmear\t             \t1.07447985972\t     \t0.299935739546\t\n",
      "    \tinfil\t             \t1.88174858781\t     \t0.17013554236\t\n",
      "    \t   li\t             \t7.93109621143\t     \t0.00485923489668\t\n",
      "    \tblast\t             \t3.52580924286\t     \t0.060420323175\t\n",
      "    \t temp\t             \t0.659090909092\t     \t0.416881070097\t\n",
      " \n",
      "** step 1: li entered:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   27\n",
      "Model:                          Logit   Df Residuals:                       25\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 20 Jan 2016   Pseudo R-squ.:                  0.2414\n",
      "Time:                        15:06:12   Log-Likelihood:                -13.036\n",
      "converged:                       True   LL-Null:                       -17.186\n",
      "                                        LLR p-value:                  0.003967\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         -3.7771      1.379     -2.740      0.006        -6.479    -1.075\n",
      "li             2.8973      1.187      2.441      0.015         0.571     5.223\n",
      "==============================================================================\n",
      "                          Model Fit Statistics \n",
      "==============================================================================\n",
      "AIC                   30.0729645051           BIC           32.6646382371    \n",
      "-2Logl                26.0729645051           SC            32.6646382371    \n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Remove  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t   li\t             \t5.95942245748\t     \t0.0146388356821\t\n",
      " \n",
      "         No (additional) Variables met the 0.35 significance level for remove into the model\n",
      "   \n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t cell\t             \t1.11825772504\t     \t0.290293920308\t\n",
      "    \tsmear\t             \t0.136910784466\t     \t0.7113716319\t\n",
      "    \tinfil\t             \t0.571492437321\t     \t0.449666470321\t\n",
      "    \tblast\t             \t0.0932043773376\t     \t0.760142306495\t\n",
      "    \t temp\t             \t1.25905986906\t     \t0.26182911958\t\n",
      " \n",
      "** step 2: temp entered:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   27\n",
      "Model:                          Logit   Df Residuals:                       24\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 20 Jan 2016   Pseudo R-squ.:                  0.2829\n",
      "Time:                        15:06:12   Log-Likelihood:                -12.324\n",
      "converged:                       True   LL-Null:                       -17.186\n",
      "                                        LLR p-value:                  0.007735\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         47.8559     46.442      1.030      0.303       -43.168   138.880\n",
      "li             3.3020      1.359      2.429      0.015         0.638     5.966\n",
      "temp         -52.4331     47.493     -1.104      0.270      -145.519    40.652\n",
      "==============================================================================\n",
      "                          Model Fit Statistics \n",
      "==============================================================================\n",
      "AIC                   30.6478222686           BIC           34.5353328666    \n",
      "-2Logl                24.6478222686           SC            31.2394960006    \n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Remove  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t   li\t             \t5.90047377967\t     \t0.0151368125598\t\n",
      "    \t temp\t             \t1.21883355547\t     \t0.269589688734\t\n",
      " \n",
      "         No (additional) Variables met the 0.35 significance level for remove into the model\n",
      "   \n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t cell\t             \t1.47007609396\t     \t0.225333688174\t\n",
      "    \tsmear\t             \t0.172968456972\t     \t0.677487009134\t\n",
      "    \tinfil\t             \t0.82745120312\t     \t0.363010577103\t\n",
      "    \tblast\t             \t1.10143188039\t     \t0.293952081059\t\n",
      " \n",
      "** step 3: cell entered:\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   27\n",
      "Model:                          Logit   Df Residuals:                       23\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 20 Jan 2016   Pseudo R-squ.:                  0.3613\n",
      "Time:                        15:06:12   Log-Likelihood:                -10.977\n",
      "converged:                       True   LL-Null:                       -17.186\n",
      "                                        LLR p-value:                  0.006079\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         67.6339     56.888      1.189      0.234       -43.864   179.131\n",
      "li             3.8671      1.778      2.175      0.030         0.382     7.352\n",
      "temp         -82.0738     61.712     -1.330      0.184      -203.028    38.880\n",
      "cell           9.6522      7.751      1.245      0.213        -5.540    24.844\n",
      "==============================================================================\n",
      "                          Model Fit Statistics \n",
      "==============================================================================\n",
      "AIC                   29.9533681094           BIC           35.1367155734    \n",
      "-2Logl                21.9533681094           SC            28.5450418414    \n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Remove  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t   li\t             \t4.72902565599\t     \t0.0296576815696\t\n",
      "    \t temp\t             \t1.76874067526\t     \t0.183538007202\t\n",
      "    \t cell\t             \t1.55068757444\t     \t0.213033964973\t\n",
      " \n",
      "         No (additional) Variables met the 0.35 significance level for remove into the model\n",
      "   \n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \tsmear\t             \t0.0955972496244\t     \t0.757178484365\t\n",
      "    \tinfil\t             \t0.0844343237647\t     \t0.771375733482\t\n",
      "    \tblast\t             \t0.0208484244049\t     \t0.885192643321\t\n",
      " \n",
      "    No (additional) Variables met the 0.3 significance level for entry into the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cell': 9.6521522246219487,\n",
       " 'const': 67.63390612810926,\n",
       " 'li': 3.867100329083915,\n",
       " 'temp': -82.073774279538782}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = StepwiseModel(data, role, slentry=0.3, slstay=0.35)\n",
    "a.beta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
